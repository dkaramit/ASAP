Things to do (no particular order):
-----------------------------------
-Maximum likelihood, least squares (applications of MCMC). Probably in C++, since I'd like to se it in my research.

-VEGAS (almost ready -- needs some minor (?) adjustments.). 1-D  ready. Needs however to make it more "user friendly", so maybe I should
make a class VEGAS, with all the functons needed,

-Solve systems of differential equations (some classic examples along with ROS3W ready! They need some documentation.
I'll also write other Rosenbrock ones.). Probably I'll do it in C++, because in python it is prohibitingly slow.
Use xtensor for numpy-like arrays in C++. I have my own small implementation, that works fine and without any memory
leaking, but xtensor is more complete! My goal afterall is to see how numerical algorithms work, and not to test my
skills on polymorphism and these things.

-Artificial neural networks. Ann with arbitrary number of hidden layers ready. Also, a number of different options
for activation and loss functions available. I have started a more object oriented version (in order to reduce complexity
and make it usable; same as in VEGAS).

-Applications of evolutionary algorithms to Anns.

-Solve optimization problems using evolutionary algorithms.

-Simulated annealing (it should be easy enough).

-Nested sampling.
======================Not sure yet=================================
-Algorithms for histograming data (in many dimensions).

-Component-wise Sampling for Metropolis [see https://theclevermachine.wordpress.com/2012/11/04/mcmc-multivariate-distributions-block-wise-component-wise-updates/]

-Gibbs sampler

-Hamiltonian  Monte  Carlo (no idea how to do this for the moment, but seems good [arXiv:1701.02434])
