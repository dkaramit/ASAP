{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to implement derivatives with respect to the weights\n",
    "\n",
    "\n",
    "Everything would be easier if I multiplied FFANN.derivatives backwards. That is,\n",
    "in order to find $\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial s^{(0)}_{p}}$ start from\n",
    "$\\dfrac{\\partial s^{(1)}_{r}}{\\partial s^{(0)}_{p}}$ and accumulate  \n",
    "products $\\dfrac{\\partial s^{(2)}_{r}}{\\partial s^{(1)}_{q}}\\dfrac{\\partial s^{(1)}_{q}}{\\partial s^{(0)}_{p}}$, $\\dfrac{\\partial s^{(3)}_{r}}{\\partial s^{(2)}_{q}}\\dfrac{\\partial s^{(2)}_{q}}{\\partial s^{(1)}_{k}}\\dfrac{\\partial s^{(1)}_{k}}{\\partial s^{(0)}_{p}}$ (with summation over repeated indices). This will help with the back propagation algorithm which is based on the observation that \n",
    "$$\n",
    "\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial w^{(l)}_{ji}} = \n",
    "\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial s^{(l+1)}_{j}} \\theta^{\\prime\\, (l+1)}_{j}s^{(l)}_{i} \\; \\text{ (no sum over j)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FeedForwardANN as FFANN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFv2(FFANN.FFANN):\n",
    "    '''\n",
    "    Very inefficient numerical derivative of s^{self.total_layers-1}_r wrt w^{l}_{ji}\n",
    "    just for testing purposes!\n",
    "    '''\n",
    "    \n",
    "    def der_w(self,r,l,j,i,h=1e-3):\n",
    "        w=self.weights[l][j][i]\n",
    "        h1=h +abs(w)*h\n",
    "        \n",
    "        self.weights[l][j][i]+=h1\n",
    "        self.evaluate()\n",
    "        f1=self.signals[self.total_layers-1][r]\n",
    "        \n",
    "        self.weights[l][j][i]+=-2*h1\n",
    "        self.evaluate()\n",
    "        f0=self.signals[self.total_layers-1][r]\n",
    "        \n",
    "        self.weights[l][j][i]+=h1\n",
    "        return (f1-f0)/(2.*h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin=FFANN.linearActivation()\n",
    "sig=FFANN.sigmoidActivation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = FFv2(2,1,[2],[sig,sig])\n",
    "brain.init_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6170447699094339], [[0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain([33.33,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6170447699094339]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.signals[brain.total_layers-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2362997327805013"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.der_w(0,1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2362997721411304"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=1\n",
    "j=0\n",
    "i=1\n",
    "x=sum([brain.weights[l][j][i] * brain.signals[l][i] for i in range(brain.nodes[l])]) + brain.biases[l][j]\n",
    "brain.signals[l][i]*brain.activations[l].derivative(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
