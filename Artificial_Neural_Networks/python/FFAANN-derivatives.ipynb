{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to implement derivatives with respect to the weights\n",
    "\n",
    "\n",
    "During ```FFANN.feedForward``` we store all $\\dfrac{\\partial s^{(l+1)}_{j}}{\\partial s^{(l)}_{i}}= \\theta^{\\prime \\, (l+1)}_{j} w^{(l)}_{ji}$\n",
    "in ```FFANN.derivatives```. For a network with $N$ layers ($N-2$ hidden + $1$ input layer + $1$ output layer), we wish to calculate  \n",
    "\n",
    "* $\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial s^{(0)}_{p}}$ . [#1](#1)\n",
    "* $\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial w^{(l)}_{ji}} = \n",
    "\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial s^{(l+1)}_{j}} \\theta^{\\prime\\, (l+1)}_{j}s^{(l)}_{i}$ (no sum over $j$). [#2](#2)\n",
    "\n",
    "\n",
    "In order to do this we can accumulate\n",
    "$$\n",
    "\\Delta^{ (0) }_{j i} = \\dfrac{\\partial s^{(N-1)}_{j}}{\\partial s^{(N-2)}_{i}} \\\\\n",
    "\\Delta^{ (1) }_{j i} = \\dfrac{\\partial s^{(N-1)}_{j}}{\\partial s^{(N-3)}_{i}}=\n",
    "\\dfrac{\\partial s^{(N-1)}_{j}}{\\partial s^{(N-2)}_{k_1}} \\cdot \n",
    "\\dfrac{\\partial s^{(N-2)}_{k_1}}{\\partial s^{(N-3)}_{i}}=\n",
    "\\Delta^{(0)}_{j k}\\cdot \\dfrac{\\partial s^{(N-2)}_{k}}{\\partial s^{(N-3)}_{i}}\n",
    "\\\\\n",
    "\\Delta^{ (2) }_{j i} = \\dfrac{\\partial s^{(N-1)}_{j}}{\\partial s^{(N-4)}_{i}}=\n",
    "\\dfrac{\\partial s^{(N-1)}_{j}}{\\partial s^{(N-2)}_{k_1}} \\cdot \n",
    "\\dfrac{\\partial s^{(N-2)}_{k_1}}{\\partial s^{(N-3)}_{k_2}}\\cdot \n",
    "\\dfrac{\\partial s^{(N-3)}_{k_2}}{\\partial s^{(N-4)}_{i}}=\n",
    "\\Delta^{(1)}_{j k}\\cdot  \\dfrac{\\partial s^{(N-3)}_{k}}{\\partial s^{(N-4)}_{i}}\\\\\n",
    "\\vdots\\\\\n",
    "\\Delta^{ (f) }_{j i} =\\Delta^{ (f-1) }_{j i} \\cdot  \\dfrac{\\partial s^{[N-(f+1)]}_{k}}{\\partial s^{[N-(f+2)]}_{i}} \\;,\n",
    "$$\n",
    "where the dot ($\\cdot$) indicates summation over repeated indices. For convinience we can also define $\\Delta^{(-1)}_{ji} = \\delta_{ij}$. \n",
    "\n",
    "\n",
    "For [#1](#1), $ f= N-2 $, i.e. $\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial s^{(0)}_{p}} = \\Delta^{(N-2)}_{ji}$.\n",
    "\n",
    "For [#2](#2),  $f= N-(l+3)$, i.e. \n",
    "$$\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial w^{(l)}_{ji}} = \n",
    "\\Delta^{ (N-(l+3)) }_{r j} \\theta^{\\prime\\, (l+1)}_{j}s^{(l)}_{i} \\qquad\\qquad\\qquad\\qquad \n",
    "\\text{ for } l \\leq N -3\n",
    "\\\\\n",
    "\\dfrac{\\partial s^{(N-1)}_{r}}{\\partial w^{(N-2)}_{ji}} = \n",
    "\\Delta^{ (-1) }_{r j} \\theta^{\\prime\\, (N-1)}_{j}s^{(N-2)}_{i} = \\delta_{r j} \\ \\theta^{\\prime\\, (N-1)}_{j}s^{(N-2)}_{i} \n",
    "\\qquad \\text{ for } l=N-2 \\; .\n",
    "$$\n",
    "\n",
    "\n",
    "Note: Similar thing holds for the derivatives with respect to the biases. Also, optimize ```FFANN.backPropagation``` **I'll have to do it later**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FeedForwardANN as FFANN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFv2(FFANN.FFANN):\n",
    "    '''\n",
    "    Very inefficient numerical derivative of s^{self.total_layers-1}_r wrt w^{l}_{ji}\n",
    "    just for testing purposes!\n",
    "    '''\n",
    "    \n",
    "    def numericalDerivative_w(self,r,l,j,i,h=1e-3):\n",
    "        N=self.total_layers-1\n",
    "        w=self.weights[l][j][i]\n",
    "        h_1=h + h*np.abs(w)\n",
    "        \n",
    "        self.weights[l][j][i]+=h_1\n",
    "\n",
    "        self.evaluate()\n",
    "        f1=self.signals[N][r]\n",
    "\n",
    "\n",
    "        self.weights[l][j][i]=w\n",
    "        self.weights[l][j][i]-=h_1\n",
    "\n",
    "        self.evaluate()\n",
    "        f0=self.signals[N][r]\n",
    "\n",
    "\n",
    "        self.weights[l][j][i]=w\n",
    "        return (f1-f0)/(2.*h_1 )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def backPropagation(self):\n",
    "        '''\n",
    "        Define Delta^{f}_{ji} = \\dfrac{\\partial s^{[N-1)]}_{k}}{\\partial s^{[N-(f+2)]}_{i}}.\n",
    "        For f=0,1,2,...N-2 this is n^{(N-1)} \\times n^{(N-(f+2))} matrix\n",
    "        \n",
    "        Notice that the Delta^{self.total_layers-2}_{ji} = \\dfrac{\\partial s^{[N-1)]}_{k}}{\\partial s^{(0)}_{i}}\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        N=self.total_layers\n",
    "        \n",
    "        self.Delta=[ [[0 for i in range(self.nodes[N-(f+2)])] for j in range(self.nodes[N-1])]  for f in range(N-1)]\n",
    "        self.Delta[0]=self.derivatives[N-2][:]\n",
    "        \n",
    "        for f in range(1,N-1):#don't run f=0\n",
    "            for j in range(self.nodes[N-1]):\n",
    "                for i in range(self.nodes[N-(f+2)]):\n",
    "                    self.Delta[f][j][i]=0\n",
    "                    for k in range(self.nodes[N-(f+1)]):\n",
    "                        self.Delta[f][j][i]+=self.Delta[f-1][j][k] * self.derivatives[N-(f+2)][k][i]\n",
    "                        \n",
    "    \n",
    "    def derivative_w(self,r,l,j,i):\n",
    "        '''\n",
    "        caclulate\n",
    "        \\dfrac{\\partial s^{(N-1)}_{r}}{\\partial w^{(l)}_{ji}} =  \n",
    "        \\Delta^{ (N-(l+3)) }_{r j} \\theta^{\\prime\\, (l+1)}_{j}s^{(l)}_{i}\n",
    "        '''\n",
    "        N=self.total_layers\n",
    "        if l==N-2:\n",
    "            if j==r:\n",
    "                sum_wx = sum( [ self.weights[l][j][k] * xi for k,xi in enumerate(self.signals[l]) ] ) \n",
    "                return self.activations[l].derivative(sum_wx+self.biases[l][j])*self.signals[l][i]    \n",
    "            else: \n",
    "                return 0\n",
    "        \n",
    "        sum_wx = sum( [ self.weights[l][j][k] * xi for k,xi in enumerate(self.signals[l]) ] ) \n",
    "        return self.Delta[N-(l+3)][r][j]*self.activations[l].derivative(sum_wx+self.biases[l][j])*self.signals[l][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin=FFANN.linearActivation()\n",
    "sig=FFANN.sigmoidActivation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = FFv2(3,4,[3,2,50,2,6,66,8,1],[lin,lin,lin,lin,lin,lin,lin,lin,sig])\n",
    "brain.init_params()\n",
    "#brain.fill_biases_with(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757 µs ± 43.9 µs per loop (mean ± std. dev. of 100 runs, 15 loops each)\n",
      "1.98 ms ± 231 µs per loop (mean ± std. dev. of 100 runs, 15 loops each)\n",
      "5.87 ms ± 182 µs per loop (mean ± std. dev. of 100 runs, 15 loops each)\n",
      "4.58 ms ± 98.9 µs per loop (mean ± std. dev. of 100 runs, 15 loops each)\n"
     ]
    }
   ],
   "source": [
    "# calculates just the output \n",
    "%timeit -n 15 -r 100 brain.evaluate()\n",
    "\n",
    "# calculates the output and the local derivatives \n",
    "%timeit -n 15 -r 100 brain([33.33,2,0.1])\n",
    "\n",
    "# calculates the output,  local derivatives, and runs backPropagation (for the Deltas)\n",
    "%timeit -n 15 -r 100 brain([33.33,2,0.1]);brain.backPropagation()\n",
    "\n",
    "# calculates the output, the local derivatives, and the derivatives wrt the signals \n",
    "%timeit -n 15 -r 100 brain.feedForwardDerivatives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
